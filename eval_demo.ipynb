{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df141065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval import evaluate \n",
    "from deepeval.metrics import AnswerRelevancyMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.models.llms.gemini_model import GeminiModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "02e022f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3e2f314",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GeminiModel(\n",
    "    model_name = \"gemini-2.0-flash\",\n",
    "    api_key = GOOGLE_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans Rele\n",
    "ar_metric = AnswerRelevancyMetric(\n",
    "    threshold = 0.8,\n",
    "    model = llm,\n",
    "    strict_mode = True,\n",
    "    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "009eba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case = LLMTestCase(\n",
    "    input=\"What if these shoes don't fit?\",\n",
    "    # Replace this with the output from your LLM app\n",
    "    actual_output=\"Taj Mahal is built by shajahan\",\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c408d8aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gemini-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">2.0</span><span style=\"color: #374151; text-decoration-color: #374151\">-flash, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gemini-\u001b[0m\u001b[1;38;2;55;65;81m2.0\u001b[0m\u001b[38;2;55;65;81m-flash, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d:\\NAVIGATE TASKS\\RAG_EVAL\\.venv\\lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for Jupyter \n",
       "support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "d:\\NAVIGATE TASKS\\RAG_EVAL\\.venv\\lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for Jupyter \n",
       "support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚ùå Answer Relevancy (score: 0.0, threshold: 1.0, strict: True, evaluation model: gemini-2.0-flash, reason: The score is 0.00 because the response included a completely irrelevant statement about the Taj Mahal when the input was about shoe fit., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: What if these shoes don't fit?\n",
      "  - actual output: Taj Mahal is built by shajahan\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Answer Relevancy: 0.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Tests finished üéâ! Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze, debug, and save evaluation results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Tests finished üéâ! Run \u001b[1;32m'deepeval view'\u001b[0m to analyze, debug, and save evaluation results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = evaluate(test_cases=[test_case], metrics=[ar_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c28a7de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationResult(test_results=[TestResult(name='test_case_0', success=False, metrics_data=[MetricData(name='Answer Relevancy', threshold=1.0, success=False, score=0.0, reason='The score is 0.00 because the response included a completely irrelevant statement about the Taj Mahal when the input was about shoe fit.', strict_mode=True, evaluation_model='gemini-2.0-flash', error=None, evaluation_cost=0.0, verbose_logs='Statements:\\n[\\n    \"Taj Mahal is built by shajahan\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The statement about the Taj Mahal is completely irrelevant to the input, which asks about shoe fit.\"\\n    }\\n]')], conversational=False, multimodal=False, input=\"What if these shoes don't fit?\", actual_output='Taj Mahal is built by shajahan', expected_output=None, context=None, retrieval_context=None, additional_metadata=None)], confident_link=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5e705b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1381aae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd48392f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951ce82e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
